{
    "train_report": "              precision    recall  f1-score   support\n\n       29783       1.00      0.99      1.00       148\n      240213       0.95      0.97      0.96       148\n      512464       0.97      0.91      0.94       132\n      560480       0.97      0.94      0.95       149\n      583064       0.94      0.96      0.95       143\n      583994       0.95      0.92      0.94       133\n      748687       0.94      0.98      0.96       174\n      806976       0.96      0.97      0.97       155\n      870118       0.87      0.90      0.89       154\n      910821       1.00      1.00      1.00       145\n      967934       0.90      0.96      0.93       146\n     1112924       0.94      0.98      0.96       139\n     1220273       0.94      0.97      0.96       139\n     1276465       0.99      0.99      0.99       145\n     1497577       0.87      0.88      0.88       128\n     2750536       0.96      0.96      0.96       138\n     2855986       0.93      0.81      0.87       139\n     2943978       0.98      0.91      0.94       143\n     3439302       0.94      0.96      0.95       128\n     6234395       0.97      0.98      0.98       127\n\n    accuracy                           0.95      2853\n   macro avg       0.95      0.95      0.95      2853\nweighted avg       0.95      0.95      0.95      2853\n",
    "dev_report": "              precision    recall  f1-score   support\n\n       29783       0.91      1.00      0.95        10\n      240213       0.76      0.87      0.81        15\n      512464       0.75      0.67      0.71         9\n      560480       0.62      0.71      0.67        14\n      583064       0.82      0.82      0.82        11\n      583994       0.93      0.76      0.84        17\n      748687       0.89      0.94      0.91        17\n      806976       0.92      0.92      0.92        13\n      870118       1.00      0.43      0.60         7\n      910821       1.00      1.00      1.00        16\n      967934       0.57      0.80      0.67        10\n     1112924       0.90      1.00      0.95         9\n     1220273       0.69      0.82      0.75        11\n     1276465       0.85      0.85      0.85        13\n     1497577       0.68      0.87      0.76        15\n     2750536       1.00      0.78      0.88         9\n     2855986       0.89      0.73      0.80        11\n     2943978       1.00      0.64      0.78        14\n     3439302       0.88      0.78      0.82         9\n     6234395       0.90      1.00      0.95         9\n\n    accuracy                           0.83       239\n   macro avg       0.85      0.82      0.82       239\nweighted avg       0.85      0.83      0.83       239\n",
    "test_report": "              precision    recall  f1-score   support\n\n       29783       1.00      1.00      1.00        14\n      240213       0.67      0.80      0.73         5\n      512464       0.94      0.88      0.91        17\n      560480       0.87      0.81      0.84        16\n      583064       0.86      0.50      0.63        12\n      583994       0.54      0.88      0.67         8\n      748687       0.91      0.83      0.87        12\n      806976       1.00      0.90      0.95        10\n      870118       0.58      1.00      0.74         7\n      910821       1.00      1.00      1.00        14\n      967934       0.69      1.00      0.82         9\n     1112924       0.88      0.93      0.90        15\n     1220273       0.83      0.91      0.87        11\n     1276465       1.00      0.87      0.93        15\n     1497577       0.83      0.77      0.80        13\n     2750536       0.85      0.85      0.85        13\n     2855986       0.89      0.89      0.89         9\n     2943978       1.00      0.64      0.78        14\n     3439302       0.86      0.86      0.86        14\n     6234395       0.91      0.91      0.91        11\n\n    accuracy                           0.86       239\n   macro avg       0.85      0.86      0.85       239\nweighted avg       0.88      0.86      0.86       239\n"
}