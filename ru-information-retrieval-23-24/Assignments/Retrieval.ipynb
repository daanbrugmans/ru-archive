{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PIUxomDsz7wg"
   },
   "source": [
    "# Retrieval exercise\n",
    "\n",
    "In this exercise, you will implement the query likelihood model with Jelinek-Mercer smoothing. This assignment builds on the previous assignment for creating a Pyserini index.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aDW16Ax3z7wk"
   },
   "source": [
    "## 1. Build the index\n",
    "Download the MS MARCO passage collection and build an index using [Pyserini](https://github.com/castorini/pyserini).\n",
    "This code is similar to PART 1 of the indexing assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "jZnegnVEz7wl"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'anserini'...\n",
      "remote: Enumerating objects: 29516, done.\u001b[K\n",
      "remote: Counting objects: 100% (3834/3834), done.\u001b[K\n",
      "remote: Compressing objects: 100% (1065/1065), done.\u001b[K\n",
      "remote: Total 29516 (delta 3226), reused 3175 (delta 2681), pack-reused 25682\u001b[K\n",
      "Receiving objects: 100% (29516/29516), 85.42 MiB | 10.14 MiB/s, done.\n",
      "Resolving deltas: 100% (19875/19875), done.\n",
      "Submodule 'tools' (https://github.com/castorini/anserini-tools.git) registered for path 'tools'\n",
      "Cloning into '/home/daanbrugmans/projects/ru-information-retrieval-23-24/Assignments/anserini/tools'...\n",
      "remote: Enumerating objects: 829, done.        \n",
      "remote: Counting objects: 100% (586/586), done.        \n",
      "remote: Compressing objects: 100% (498/498), done.        \n",
      "remote: Total 829 (delta 114), reused 549 (delta 87), pack-reused 243        \n",
      "Receiving objects: 100% (829/829), 192.26 MiB | 9.89 MiB/s, done.\n",
      "Resolving deltas: 100% (198/198), done.\n",
      "Submodule path 'tools': checked out '95d06f60043837a309331ffdbee7560dd1676313'\n",
      "collection.tsv\n",
      "Converting collection...\n",
      "Converted 0 docs, writing into file 1\n",
      "Converted 100,000 docs, writing into file 1\n",
      "Converted 200,000 docs, writing into file 1\n",
      "Converted 300,000 docs, writing into file 1\n",
      "Converted 400,000 docs, writing into file 1\n",
      "Converted 500,000 docs, writing into file 1\n",
      "Converted 600,000 docs, writing into file 1\n",
      "Converted 700,000 docs, writing into file 1\n",
      "Converted 800,000 docs, writing into file 1\n",
      "Converted 900,000 docs, writing into file 1\n",
      "Converted 1,000,000 docs, writing into file 2\n",
      "Converted 1,100,000 docs, writing into file 2\n",
      "Converted 1,200,000 docs, writing into file 2\n",
      "Converted 1,300,000 docs, writing into file 2\n",
      "Converted 1,400,000 docs, writing into file 2\n",
      "Converted 1,500,000 docs, writing into file 2\n",
      "Converted 1,600,000 docs, writing into file 2\n",
      "Converted 1,700,000 docs, writing into file 2\n",
      "Converted 1,800,000 docs, writing into file 2\n",
      "Converted 1,900,000 docs, writing into file 2\n",
      "Converted 2,000,000 docs, writing into file 3\n",
      "Converted 2,100,000 docs, writing into file 3\n",
      "Converted 2,200,000 docs, writing into file 3\n",
      "Converted 2,300,000 docs, writing into file 3\n",
      "Converted 2,400,000 docs, writing into file 3\n",
      "Converted 2,500,000 docs, writing into file 3\n",
      "Converted 2,600,000 docs, writing into file 3\n",
      "Converted 2,700,000 docs, writing into file 3\n",
      "Converted 2,800,000 docs, writing into file 3\n",
      "Converted 2,900,000 docs, writing into file 3\n",
      "Converted 3,000,000 docs, writing into file 4\n",
      "Converted 3,100,000 docs, writing into file 4\n",
      "Converted 3,200,000 docs, writing into file 4\n",
      "Converted 3,300,000 docs, writing into file 4\n",
      "Converted 3,400,000 docs, writing into file 4\n",
      "Converted 3,500,000 docs, writing into file 4\n",
      "Converted 3,600,000 docs, writing into file 4\n",
      "Converted 3,700,000 docs, writing into file 4\n",
      "Converted 3,800,000 docs, writing into file 4\n",
      "Converted 3,900,000 docs, writing into file 4\n",
      "Converted 4,000,000 docs, writing into file 5\n",
      "Converted 4,100,000 docs, writing into file 5\n",
      "Converted 4,200,000 docs, writing into file 5\n",
      "Converted 4,300,000 docs, writing into file 5\n",
      "Converted 4,400,000 docs, writing into file 5\n",
      "Converted 4,500,000 docs, writing into file 5\n",
      "Converted 4,600,000 docs, writing into file 5\n",
      "Converted 4,700,000 docs, writing into file 5\n",
      "Converted 4,800,000 docs, writing into file 5\n",
      "Converted 4,900,000 docs, writing into file 5\n",
      "Converted 5,000,000 docs, writing into file 6\n",
      "Converted 5,100,000 docs, writing into file 6\n",
      "Converted 5,200,000 docs, writing into file 6\n",
      "Converted 5,300,000 docs, writing into file 6\n",
      "Converted 5,400,000 docs, writing into file 6\n",
      "Converted 5,500,000 docs, writing into file 6\n",
      "Converted 5,600,000 docs, writing into file 6\n",
      "Converted 5,700,000 docs, writing into file 6\n",
      "Converted 5,800,000 docs, writing into file 6\n",
      "Converted 5,900,000 docs, writing into file 6\n",
      "Converted 6,000,000 docs, writing into file 7\n",
      "Converted 6,100,000 docs, writing into file 7\n",
      "Converted 6,200,000 docs, writing into file 7\n",
      "Converted 6,300,000 docs, writing into file 7\n",
      "Converted 6,400,000 docs, writing into file 7\n",
      "Converted 6,500,000 docs, writing into file 7\n",
      "Converted 6,600,000 docs, writing into file 7\n",
      "Converted 6,700,000 docs, writing into file 7\n",
      "Converted 6,800,000 docs, writing into file 7\n",
      "Converted 6,900,000 docs, writing into file 7\n",
      "Converted 7,000,000 docs, writing into file 8\n",
      "Converted 7,100,000 docs, writing into file 8\n",
      "Converted 7,200,000 docs, writing into file 8\n",
      "Converted 7,300,000 docs, writing into file 8\n",
      "Converted 7,400,000 docs, writing into file 8\n",
      "Converted 7,500,000 docs, writing into file 8\n",
      "Converted 7,600,000 docs, writing into file 8\n",
      "Converted 7,700,000 docs, writing into file 8\n",
      "Converted 7,800,000 docs, writing into file 8\n",
      "Converted 7,900,000 docs, writing into file 8\n",
      "Converted 8,000,000 docs, writing into file 9\n",
      "Converted 8,100,000 docs, writing into file 9\n",
      "Converted 8,200,000 docs, writing into file 9\n",
      "Converted 8,300,000 docs, writing into file 9\n",
      "Converted 8,400,000 docs, writing into file 9\n",
      "Converted 8,500,000 docs, writing into file 9\n",
      "Converted 8,600,000 docs, writing into file 9\n",
      "Converted 8,700,000 docs, writing into file 9\n",
      "Converted 8,800,000 docs, writing into file 9\n",
      "Done!\n",
      "WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.\n",
      "2023-09-27 19:56:44,599 INFO  [main] index.IndexCollection (IndexCollection.java:380) - Setting log level to INFO\n",
      "2023-09-27 19:56:44,603 INFO  [main] index.IndexCollection (IndexCollection.java:383) - Starting indexer...\n",
      "2023-09-27 19:56:44,603 INFO  [main] index.IndexCollection (IndexCollection.java:384) - ============ Loading Parameters ============\n",
      "2023-09-27 19:56:44,604 INFO  [main] index.IndexCollection (IndexCollection.java:385) - DocumentCollection path: Data/collection_jsonl\n",
      "2023-09-27 19:56:44,604 INFO  [main] index.IndexCollection (IndexCollection.java:386) - CollectionClass: JsonCollection\n",
      "2023-09-27 19:56:44,605 INFO  [main] index.IndexCollection (IndexCollection.java:387) - Generator: DefaultLuceneDocumentGenerator\n",
      "2023-09-27 19:56:44,605 INFO  [main] index.IndexCollection (IndexCollection.java:388) - Threads: 9\n",
      "2023-09-27 19:56:44,606 INFO  [main] index.IndexCollection (IndexCollection.java:389) - Language: en\n",
      "2023-09-27 19:56:44,606 INFO  [main] index.IndexCollection (IndexCollection.java:390) - Stemmer: porter\n",
      "2023-09-27 19:56:44,606 INFO  [main] index.IndexCollection (IndexCollection.java:391) - Keep stopwords? false\n",
      "2023-09-27 19:56:44,607 INFO  [main] index.IndexCollection (IndexCollection.java:392) - Stopwords: null\n",
      "2023-09-27 19:56:44,607 INFO  [main] index.IndexCollection (IndexCollection.java:393) - Store positions? true\n",
      "2023-09-27 19:56:44,608 INFO  [main] index.IndexCollection (IndexCollection.java:394) - Store docvectors? true\n",
      "2023-09-27 19:56:44,610 INFO  [main] index.IndexCollection (IndexCollection.java:395) - Store document \"contents\" field? false\n",
      "2023-09-27 19:56:44,611 INFO  [main] index.IndexCollection (IndexCollection.java:396) - Store document \"raw\" field? true\n",
      "2023-09-27 19:56:44,612 INFO  [main] index.IndexCollection (IndexCollection.java:397) - Additional fields to index: []\n",
      "2023-09-27 19:56:44,613 INFO  [main] index.IndexCollection (IndexCollection.java:398) - Optimize (merge segments)? false\n",
      "2023-09-27 19:56:44,614 INFO  [main] index.IndexCollection (IndexCollection.java:399) - Whitelist: null\n",
      "2023-09-27 19:56:44,615 INFO  [main] index.IndexCollection (IndexCollection.java:400) - Pretokenized?: false\n",
      "2023-09-27 19:56:44,616 INFO  [main] index.IndexCollection (IndexCollection.java:401) - Index path: Data/indexes/lucene-index-msmarco-passage\n",
      "2023-09-27 19:56:44,623 INFO  [main] index.IndexCollection (IndexCollection.java:481) - ============ Indexing Collection ============\n",
      "2023-09-27 19:56:44,643 INFO  [main] index.IndexCollection (IndexCollection.java:468) - Using DefaultEnglishAnalyzer\n",
      "2023-09-27 19:56:44,644 INFO  [main] index.IndexCollection (IndexCollection.java:469) - Stemmer: porter\n",
      "2023-09-27 19:56:44,644 INFO  [main] index.IndexCollection (IndexCollection.java:470) - Keep stopwords? false\n",
      "2023-09-27 19:56:44,645 INFO  [main] index.IndexCollection (IndexCollection.java:471) - Stopwords file: null\n",
      "2023-09-27 19:56:44,836 INFO  [main] index.IndexCollection (IndexCollection.java:510) - Thread pool with 9 threads initialized.\n",
      "2023-09-27 19:56:44,836 INFO  [main] index.IndexCollection (IndexCollection.java:512) - Initializing collection in Data/collection_jsonl\n",
      "2023-09-27 19:56:44,845 INFO  [main] index.IndexCollection (IndexCollection.java:521) - 9 files found\n",
      "2023-09-27 19:56:44,846 INFO  [main] index.IndexCollection (IndexCollection.java:522) - Starting to index...\n",
      "2023-09-27 19:57:44,870 INFO  [main] index.IndexCollection (IndexCollection.java:536) - 0.00% of files completed, 2,230,000 documents indexed\n",
      "2023-09-27 19:58:44,872 INFO  [main] index.IndexCollection (IndexCollection.java:536) - 0.00% of files completed, 4,510,000 documents indexed\n",
      "2023-09-27 19:59:44,874 INFO  [main] index.IndexCollection (IndexCollection.java:536) - 0.00% of files completed, 6,750,000 documents indexed\n",
      "2023-09-27 20:00:07,677 DEBUG [pool-2-thread-9] index.IndexCollection$LocalIndexerThread (IndexCollection.java:345) - collection_jsonl/docs08.json: 841823 docs added.\n",
      "2023-09-27 20:00:44,881 INFO  [main] index.IndexCollection (IndexCollection.java:536) - 11.11% of files completed, 8,441,823 documents indexed\n",
      "2023-09-27 20:00:46,462 DEBUG [pool-2-thread-5] index.IndexCollection$LocalIndexerThread (IndexCollection.java:345) - collection_jsonl/docs07.json: 1000000 docs added.\n",
      "2023-09-27 20:00:51,110 DEBUG [pool-2-thread-7] index.IndexCollection$LocalIndexerThread (IndexCollection.java:345) - collection_jsonl/docs01.json: 1000000 docs added.\n",
      "2023-09-27 20:00:53,092 DEBUG [pool-2-thread-8] index.IndexCollection$LocalIndexerThread (IndexCollection.java:345) - collection_jsonl/docs00.json: 1000000 docs added.\n",
      "2023-09-27 20:00:56,970 DEBUG [pool-2-thread-6] index.IndexCollection$LocalIndexerThread (IndexCollection.java:345) - collection_jsonl/docs04.json: 1000000 docs added.\n",
      "2023-09-27 20:00:57,933 DEBUG [pool-2-thread-1] index.IndexCollection$LocalIndexerThread (IndexCollection.java:345) - collection_jsonl/docs05.json: 1000000 docs added.\n",
      "2023-09-27 20:00:58,058 DEBUG [pool-2-thread-2] index.IndexCollection$LocalIndexerThread (IndexCollection.java:345) - collection_jsonl/docs02.json: 1000000 docs added.\n",
      "2023-09-27 20:00:58,217 DEBUG [pool-2-thread-4] index.IndexCollection$LocalIndexerThread (IndexCollection.java:345) - collection_jsonl/docs03.json: 1000000 docs added.\n",
      "2023-09-27 20:01:05,544 DEBUG [pool-2-thread-3] index.IndexCollection$LocalIndexerThread (IndexCollection.java:345) - collection_jsonl/docs06.json: 1000000 docs added.\n",
      "2023-09-27 20:03:44,931 INFO  [main] index.IndexCollection (IndexCollection.java:578) - Indexing Complete! 8,841,823 documents indexed\n",
      "2023-09-27 20:03:44,932 INFO  [main] index.IndexCollection (IndexCollection.java:579) - ============ Final Counter Values ============\n",
      "2023-09-27 20:03:44,932 INFO  [main] index.IndexCollection (IndexCollection.java:580) - indexed:        8,841,823\n",
      "2023-09-27 20:03:44,933 INFO  [main] index.IndexCollection (IndexCollection.java:581) - unindexable:            0\n",
      "2023-09-27 20:03:44,934 INFO  [main] index.IndexCollection (IndexCollection.java:582) - empty:                  0\n",
      "2023-09-27 20:03:44,936 INFO  [main] index.IndexCollection (IndexCollection.java:583) - skipped:                0\n",
      "2023-09-27 20:03:44,937 INFO  [main] index.IndexCollection (IndexCollection.java:584) - errors:                 0\n",
      "2023-09-27 20:03:44,961 INFO  [main] index.IndexCollection (IndexCollection.java:587) - Total 8,841,823 documents indexed in 00:07:00\n"
     ]
    }
   ],
   "source": [
    "# NOTE: I comment out the pip install statements because I do them manually.\n",
    "# NOTE: The file paths here may slightly alter from the original file paths.\n",
    "    # This is so that the paths fit my local structure.\n",
    "\n",
    "# !pip install pyserini\n",
    "# !pip install faiss-cpu\n",
    "\n",
    "!git clone https://github.com/castorini/anserini.git --recurse-submodules\n",
    "\n",
    "# NOTE: Commented out because redownloading this file takes 20+ minutes.\n",
    "# !wget https://msmarco.blob.core.windows.net/msmarcoranking/collection.tar.gz -P Data/\n",
    "!tar xvfz Data/collection.tar.gz -C Data/\n",
    "\n",
    "!cd anserini && python tools/scripts/msmarco/convert_collection_to_jsonl.py \\\n",
    " --collection-path ../Data/collection.tsv --output-folder ../Data/collection_jsonl\n",
    "\n",
    "!rm Data/*.tsv\n",
    "!rm -rf sample_data\n",
    "\n",
    "!python -m pyserini.index.lucene -collection JsonCollection -generator DefaultLuceneDocumentGenerator -threads 9 \\\n",
    "-input Data/collection_jsonl -index Data/indexes/lucene-index-msmarco-passage -storePositions -storeDocvectors -storeRaw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5y7fHsrjz7wn"
   },
   "source": [
    "## 2. Download and read the query file\n",
    "You will rank MSMARCO passages for this set of queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-09-27 20:03:45--  http://gem.cs.ru.nl/IR-Course/queries.txt\n",
      "Resolving gem.cs.ru.nl (gem.cs.ru.nl)... 131.174.31.31\n",
      "Connecting to gem.cs.ru.nl (gem.cs.ru.nl)|131.174.31.31|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 2275 (2.2K) [text/plain]\n",
      "Saving to: ‘Data/queries.txt’\n",
      "\n",
      "queries.txt         100%[===================>]   2.22K  --.-KB/s    in 0s      \n",
      "\n",
      "2023-09-27 20:03:46 (88.6 MB/s) - ‘Data/queries.txt’ saved [2275/2275]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget http://gem.cs.ru.nl/IR-Course/queries.txt -P Data/\n",
    "    \n",
    "queries = dict()\n",
    "with open(\"Data/queries.txt\", \"r\") as f:\n",
    "    for line in f:\n",
    "        cols = line.split(\"\\t\")\n",
    "        queries[cols[0].strip()] = cols[1].strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tqQ9dLKGz7wo"
   },
   "source": [
    "## 3. Implement the retrieval model\n",
    "You will implement language model with Jelinek-Mercer (JM) smoothing:\n",
    "$$score(q,d) = \\sum_{t \\in q} log ((1-\\lambda) \\frac{c(t, d)}{|d|} + \\lambda \\frac{c (t, C)}{|C|}),$$\n",
    "where $c (t, d)$ and $c (t, C)$ represent frequency of a term in a document and collection, respectively.\n",
    "\n",
    "**Notes about your implementation:**\n",
    "- Skip a term if it does not exist in the whole collection. This avoids $log(0)$.\n",
    "- Make sure to use the right form of a query (analyzed vs. not analyzed)\n",
    "- Use natural logarithm \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-aTvGGMez7wo"
   },
   "source": [
    "### 3.1. Obtain collection length\n",
    "In this code, the global variable `len_C` denotes collection length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "wm_dvrdGz7wp"
   },
   "outputs": [],
   "source": [
    "from pyserini.index.lucene import IndexReader\n",
    "\n",
    "global len_C\n",
    "\n",
    "# =======Your code=======\n",
    "index_reader = IndexReader(\"Data/indexes/lucene-index-msmarco-passage\")\n",
    "len_C = index_reader.stats()[\"total_terms\"]\n",
    "# ======================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SLw-PtK7z7wp"
   },
   "source": [
    "Run this to test your code. If everything is correct, you should not get errors here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "VPp4gWOcz7wq"
   },
   "outputs": [],
   "source": [
    "assert len_C == 352316036"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZsAxcO6Sz7wq"
   },
   "source": [
    "### 3.2. Obtain document length\n",
    "\n",
    "Here you need compute the length of document (as it is stored in the index).\n",
    "\n",
    "*Hint: You first need to get the document vector from your Pyserini index. Consult [Pyseniri documentation](https://github.com/castorini/pyserini/blob/master/docs/usage-indexreader.md) to find the right function.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "LgNvo5ySz7wq"
   },
   "outputs": [],
   "source": [
    "def len_doc(d):\n",
    "    # =======Your code=======\n",
    "    document_vector = index_reader.get_document_vector(d)\n",
    "    len_d = sum([value for _, value in document_vector.items()])\n",
    "    # =======================\n",
    "    return len_d  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "pyTXkaStz7wr"
   },
   "outputs": [],
   "source": [
    "# Test your code\n",
    "assert len_doc(\"2674124\") == 31"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0mo_ZvZZz7wr"
   },
   "source": [
    "### 3.3. Obtain collection frequency of a term\n",
    "\n",
    "Obtain number of times a term appers in the whole collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "e5DjkOL4z7ws"
   },
   "outputs": [],
   "source": [
    "def coll_freq(t):\n",
    "    # =======Your code=======\n",
    "    cf = index_reader.get_term_counts(t)[1]  \n",
    "    # =======================\n",
    "    return cf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "jORCqhcYz7ws"
   },
   "outputs": [],
   "source": [
    "# Test your code\n",
    "assert coll_freq(\"record\") == 226439"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IskuP3d0z7wt"
   },
   "source": [
    "### 3.4. Obtain term frequency\n",
    "\n",
    "Obtain number of times a term appears in a document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "_NACqgxZz7wt"
   },
   "outputs": [],
   "source": [
    "def term_freq(t, d):\n",
    "    # =======Your code=======\n",
    "    document_vector = index_reader.get_document_vector(d)\n",
    "    \n",
    "    if t not in document_vector:\n",
    "        return 0\n",
    "    \n",
    "    tf = document_vector[t]\n",
    "    # =======================\n",
    "    return tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "r_zvVALfz7wt"
   },
   "outputs": [],
   "source": [
    "# Test your code\n",
    "assert term_freq(\"record\", \"2674124\") == 2\n",
    "assert term_freq(\"presence\", \"2674124\") == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rPNZ3Q-Zz7wu"
   },
   "source": [
    "### 3.5. Compute JM-smoothed probability for a single term\n",
    "\n",
    "Here, you need to implement the following formula:\n",
    "\n",
    "$$P_{JM}(t,d) = (1-\\lambda) \\frac{c(t, d)}{|d|} + \\lambda \\frac{c (t, C)}{|C|}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "oxP7NRtnz7wu"
   },
   "outputs": [],
   "source": [
    "def prob_t_Md(t, d, lambd):\n",
    "    # =======Your code=======\n",
    "    p_t_Md = (1 - lambd) * term_freq(t, d)/len_doc(d) + lambd * coll_freq(t)/len_C\n",
    "    # =======================\n",
    "    return p_t_Md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "Z05E7Tniz7wu"
   },
   "outputs": [],
   "source": [
    "# Test your code\n",
    "assert prob_t_Md(\"record\", \"2674124\", 0.1) == 0.05812878768549357\n",
    "assert prob_t_Md(\"darcig\", \"2674124\", 0.1) == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ayHxi_bFz7wv"
   },
   "source": [
    "### 3.6. Compute JM-smoothed probability for a query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "s6gTHha7z7wv"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def score_doc(q, d, lambd):\n",
    "    # =======Your code=======\n",
    "    p_q_Md = 0\n",
    "    \n",
    "    for term in q:\n",
    "        prob_t_Md_for_term = prob_t_Md(term, d, lambd)\n",
    "        \n",
    "        if prob_t_Md_for_term != 0:\n",
    "            p_q_Md += math.log(prob_t_Md_for_term)\n",
    "    # =======================\n",
    "    return p_q_Md         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "JTTwVuCQz7ww"
   },
   "outputs": [],
   "source": [
    "q1 = index_reader.analyze(\"are naturalization records public\")\n",
    "q2 = index_reader.analyze(\"kemeet land\")\n",
    "doc = \"2674124\"\n",
    "assert score_doc(q1, doc, 0.1) == -9.227787624348021\n",
    "assert score_doc(q2, doc, 0.1) == -10.254756777887694"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i8n2OLTUz7wx"
   },
   "source": [
    "## 4. Rank documents for the given queries\n",
    "Ranking is done in two steps:\n",
    "1. First pass retrieval: Use a fast ranker (i.e., Pyserini LuceneSearcher) ro rank all documents for a given query.\n",
    "2. Second pass retrieval: Re-rank top-100 documents from the 1st pass retrieval using your retrieval model. This is to make the ranking process efficient.\n",
    "\n",
    "**Notes:**\n",
    "- You need to change the default values of LuceneSearcher functions to obtain top-100 documents\n",
    "- Set the value of lambda to 0.1\n",
    "- Store your final ranking results in the `results` variable. Every item in the `results` list is a list containing queryID, documentID, and score. This is an example how the content of results should look like:\n",
    "\n",
    "`[['23849', '4348282', -10.65],\n",
    " ['23849', '7119957', -12.63],\n",
    " ['23849', '', -17.687729001682484], \n",
    " ...]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daanbrugmans/projects/ru-information-retrieval-23-24/env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from pyserini.search.lucene import LuceneSearcher\n",
    "\n",
    "results = []\n",
    "searcher = LuceneSearcher(\"Data/indexes/lucene-index-msmarco-passage\")\n",
    "for qid, q in queries.items():\n",
    "    # =======Your code=======\n",
    "    lucene_searcher_top_100_hits = searcher.search(q, 100)\n",
    "    analyzed_query = index_reader.analyze(q)\n",
    "    \n",
    "    for lucene_searcher_hit in lucene_searcher_top_100_hits:\n",
    "        score = score_doc(analyzed_query, lucene_searcher_hit.docid, 0.1)\n",
    "        results.append([qid, lucene_searcher_hit.docid, score])\n",
    "    # ======================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "_tLfZfYyz7wx"
   },
   "outputs": [],
   "source": [
    "# Test your code\n",
    "assert round(sum([item[2] for item in results]), 3) == -160109.875"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4zUuHqbCz7wy"
   },
   "source": [
    "Write your results into a file.\n",
    "Submit this file together with the completed notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-iex2B2Bz7wy",
    "outputId": "0dd37f20-8a82-4d53-8a8b-e30f0523dbf1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "246890"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check duplicates\n",
    "check = set()\n",
    "for res in results:\n",
    "    if ((res[0], res[1])) in check:\n",
    "        raise Exception(\"Error: Duplicate query-doc is found\", res[0], res[1])\n",
    "    check.add((res[0], res[1]))\n",
    "\n",
    "# write results in a file\n",
    "output_str = \"\\n\".join([l[0] + \"\\tQ0\\t\" + l[1] + \"\\t0\\t\" + str(l[2]) + \"\\tlm_jm\" for l in results])\n",
    "open(\"lm_jm.run\", \"w\").write(output_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nr17hR57z7wy"
   },
   "source": [
    "## Handing in\n",
    "Submit the result file (ranked documents), the filled-in notebook, and the pdf version of your notebook:\n",
    "\n",
    "- The result file should be named STUDENTNUMBER_FIRSTNAME_LASTNAME_lm_jm.run\n",
    "- The notebook should be named STUDENTNUMBER_FIRSTNAME_LASTNAME_retrieval.ipynb\n",
    "- The pdf version of your notebook should be named STUDENTNUMBER_FIRSTNAME_LASTNAME_retrieval.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bDNNeoF9z7wz"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0cddc2f96c204ca493788831a533940b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c4a378fd626a4d3ba817f47eb701e968",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_99809e804e3447599d028391df329048",
      "value": 0
     }
    },
    "1cfb30a27bb54543b62e653378288537": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_b5c39fe139f4461489457a40ffba01ff",
       "IPY_MODEL_0cddc2f96c204ca493788831a533940b",
       "IPY_MODEL_79cad626311b4ba68e4b7352894f43df"
      ],
      "layout": "IPY_MODEL_ad8ed732b91e4d33a3d0c110a51f1658"
     }
    },
    "4bbbbb9f02364c65962427e7c68c4bbe": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "79cad626311b4ba68e4b7352894f43df": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_dd722d4e767f4d8cb4ed3603eb9e990f",
      "placeholder": "​",
      "style": "IPY_MODEL_4bbbbb9f02364c65962427e7c68c4bbe",
      "value": " 0/0 [00:00&lt;?, ?it/s]"
     }
    },
    "9688e1cef6354bb1a58bdf160e244dc3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "99809e804e3447599d028391df329048": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "ad8ed732b91e4d33a3d0c110a51f1658": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b5c39fe139f4461489457a40ffba01ff": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9688e1cef6354bb1a58bdf160e244dc3",
      "placeholder": "​",
      "style": "IPY_MODEL_e4682415fc234b3d8b751ac961e4aecd",
      "value": ""
     }
    },
    "c4a378fd626a4d3ba817f47eb701e968": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "20px"
     }
    },
    "dd722d4e767f4d8cb4ed3603eb9e990f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e4682415fc234b3d8b751ac961e4aecd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
